{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, TimeSeriesSplit, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"../datasets/train.csv\")\n",
    "train_df = pd.read_csv(\n",
    "    '../datasets/train.csv',\n",
    "    usecols=['date', 'num_sold'],\n",
    "    skiprows=lambda x: x > 0 and np.random.rand() > 0.1\n",
    ")\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming & Forecasting data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Membuat fitur lag dan fitur terkait tanggal untuk supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data, lags=3, date_features=None, dropna=True, fill_value=None):\n",
    "    \"\"\"\n",
    "    Membuat fitur lag dan fitur terkait tanggal untuk supervised learning.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame input dengan kolom 'ds' (datetime) dan 'y' (target).\n",
    "        lags (int): Jumlah lag yang akan dibuat. Defaultnya 3.\n",
    "        date_features (list, optional): List fitur tanggal yang akan dibuat. \n",
    "            Pilihan: 'year', 'quarter', 'month', 'dayofweek', 'dayofyear', 'weekofyear'.\n",
    "            Jika None, hanya 'month' dan 'dayofweek' yang dibuat.\n",
    "        dropna (bool, optional): Apakah akan menghapus baris dengan NaN (karena lag). Defaultnya True.\n",
    "        fill_value (any, optional): Nilai yang akan digunakan untuk mengisi NaN jika dropna=False. Defaultnya None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame dengan fitur-fitur baru.\n",
    "        int: Jumlah baris yang dihapus jika dropna=True, atau 0 jika dropna=False.\n",
    "        Mengembalikan None jika input tidak valid.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: Jika input data bukan DataFrame atau kolom 'ds' bukan datetime.\n",
    "        ValueError: Jika lags kurang dari 1.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise TypeError(\"Input data harus berupa DataFrame.\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(data['ds']):\n",
    "        raise TypeError(\"Kolom 'ds' harus bertipe datetime.\")\n",
    "    if lags < 1:\n",
    "        raise ValueError(\"Jumlah lag harus minimal 1.\")\n",
    "\n",
    "    lagged_data = {f\"lag_{i}\": data['y'].shift(i) for i in range(1, lags + 1)}\n",
    "    lagged_df = pd.DataFrame(lagged_data)\n",
    "\n",
    "    if date_features is None:\n",
    "        date_features = ['month', 'dayofweek']\n",
    "\n",
    "    date_feature_data = {}\n",
    "    for feature in date_features:\n",
    "        try:\n",
    "            date_feature_data[feature] = getattr(data['ds'].dt, feature)\n",
    "        except AttributeError:\n",
    "            print(f\"Fitur tanggal {feature} tidak dikenal atau bukan atribut datetime. Melewati.\")\n",
    "\n",
    "    date_features_df = pd.DataFrame(date_feature_data)\n",
    "\n",
    "    result = pd.concat([data, lagged_df, date_features_df], axis=1)\n",
    "\n",
    "    rows_dropped = 0\n",
    "    if dropna:\n",
    "        rows_dropped = len(result)\n",
    "        result.dropna(inplace=True)\n",
    "        rows_dropped -= len(result)\n",
    "    elif fill_value is not None:\n",
    "        result.fillna(fill_value, inplace=True)\n",
    "\n",
    "    return result, rows_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load & prepare new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris yang dihapus: 3\n"
     ]
    }
   ],
   "source": [
    "train_df.rename(columns={\"date\": \"ds\", \"num_sold\": \"y\"}, inplace=True)\n",
    "train_df['ds'] = pd.to_datetime(train_df['ds'])\n",
    "\n",
    "# Unpacking tuple: data_df akan berisi DataFrame, dropped akan berisi jumlah baris yang dihapus\n",
    "data, dropped = create_features(train_df)\n",
    "\n",
    "# Sekarang Anda bisa memanggil head() pada DataFrame\n",
    "print(f\"Jumlah baris yang dihapus: {dropped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cari hyperparameter terbaik menggunakan grid search dan random search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"y\", \"ds\"])\n",
    "y = data[\"y\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# TimeSeriesSplit untuk time series data\n",
    "tscv = TimeSeriesSplit(n_splits=5) # 5 fold cross validation\n",
    "\n",
    "# Definisikan parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "# Inisialisasi model\n",
    "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=tscv, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1) # n_jobs=-1 menggunakan semua core CPU\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", np.sqrt(-grid_search.best_score_))\n",
    "\n",
    "# Random Search (Jika rentang parameter sangat luas)\n",
    "n_iter_search = 20 # Jumlah iterasi random search\n",
    "random_search = RandomizedSearchCV(model, param_grid, n_iter=n_iter_search, cv=tscv, scoring='neg_mean_squared_error', verbose=1, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nRandom Search\")\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best score:\", np.sqrt(-random_search.best_score_))\n",
    "\n",
    "# Evaluasi model terbaik pada data test\n",
    "best_model = grid_search.best_estimator_ # atau random_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE pada data test dengan parameter terbaik: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators=50, learning_rate=0.01, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hitung score RMSE, MAE, MAPE, dan hitung naive prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Naive forecast\n",
    "naive_pred = y_test.shift(1)  # Menggunakan nilai sebelumnya sebagai prediksi\n",
    "naive_mae = mean_absolute_error(y_test[1:], naive_pred[1:])\n",
    "naive_rmse = np.sqrt(mean_squared_error(y_test[1:], naive_pred[1:]))\n",
    "\n",
    "print(f\"Naive Forecast MAE: {naive_mae:.2f}\")\n",
    "print(f\"Naive Forecast RMSE: {naive_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediksi sales untuk satu tahun ke depan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_steps = 365\n",
    "lags = 5  # Sesuaikan dengan jumlah lag saat melatih model\n",
    "last_known_data = data.iloc[-lags:].copy()  # Gunakan sejumlah baris terakhir sesuai jumlah lag\n",
    "future_forecast = []\n",
    "\n",
    "for _ in range(future_steps):\n",
    "    # Ambil fitur lagging terakhir\n",
    "    if len(last_known_data) < lags:\n",
    "        raise ValueError(f\"Insufficient data for lag features. Expected: {lags}, got: {len(last_known_data)}\")\n",
    "    \n",
    "    future_input = last_known_data[\"y\"].values[-lags:].reshape(1, -1)\n",
    "    \n",
    "    # Prediksi nilai berikutnya\n",
    "    pred = model.predict(future_input)[0]\n",
    "    future_forecast.append(pred)\n",
    "    \n",
    "    # Perbarui data lag\n",
    "    last_known_data = pd.concat(\n",
    "        [last_known_data.iloc[1:], pd.DataFrame({\"y\": [pred]})], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.copy()\n",
    "train_data[\"Type\"] = \"Train Data\"\n",
    "\n",
    "forecast_data = pd.DataFrame({\n",
    "    \"ds\": pd.date_range(start=train_data[\"ds\"].iloc[-1], periods=future_steps, freq=\"D\"),\n",
    "    \"y\": future_forecast,\n",
    "    \"Type\": \"Forecast\",\n",
    "})\n",
    "\n",
    "# Gabungkan data historis dan prediksi untuk visualisasi\n",
    "combined_data = pd.concat([train_data, forecast_data], ignore_index=True)\n",
    "\n",
    "# Plot Data Historis dan Prediksi\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.lineplot(data=combined_data, x=\"ds\", y=\"y\", hue=\"Type\", palette=[\"blue\", \"red\"], linewidth=1.5)\n",
    "\n",
    "# Judul dan Label\n",
    "plt.title(\"Visualisasi Data Historis dan Prediksi\", fontsize=16)\n",
    "plt.xlabel(\"Tanggal\", fontsize=12)\n",
    "plt.ylabel(\"Jumlah Terjual\", fontsize=12)\n",
    "plt.legend(title=\"Tipe Data\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With confidence interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Historis dan Prediksi dengan Interval Kepercayaan\n",
    "forecast_data = pd.DataFrame({\n",
    "    \"ds\": pd.date_range(start=data[\"ds\"].iloc[-1], periods=future_steps, freq=\"D\"),\n",
    "    \"y\": future_forecast,\n",
    "    \"yhat_lower\": np.array(future_forecast) * 0.9,  # Contoh interval bawah (90% dari nilai)\n",
    "    \"yhat_upper\": np.array(future_forecast) * 1.1,  # Contoh interval atas (110% dari nilai)\n",
    "    \"Type\": \"Forecast\",\n",
    "})\n",
    "\n",
    "# Gabungkan data historis dan prediksi\n",
    "combined_data = pd.concat([data, forecast_data], ignore_index=True)\n",
    "\n",
    "# Plot Data Historis dan Prediksi\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.lineplot(data=combined_data, x=\"ds\", y=\"y\", hue=\"Type\", palette=\"Blues_d\", linewidth=1.5)\n",
    "\n",
    "# Tambahkan Area Confidence Interval\n",
    "plt.fill_between(\n",
    "    forecast_data[\"ds\"],\n",
    "    forecast_data[\"yhat_lower\"],\n",
    "    forecast_data[\"yhat_upper\"],\n",
    "    color=\"red\",\n",
    "    alpha=0.3,\n",
    "    label=\"Confidence Interval\",\n",
    ")\n",
    "\n",
    "# Judul dan Label\n",
    "plt.title(\"Visualisasi Data Historis dan Prediksi dengan Interval Kepercayaan\", fontsize=16)\n",
    "plt.xlabel(\"Tanggal\", fontsize=12)\n",
    "plt.ylabel(\"Jumlah Terjual\", fontsize=12)\n",
    "plt.legend(title=\"Tipe Data\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(residuals, label=\"Residuals\", color=\"orange\")\n",
    "plt.axhline(0, linestyle=\"--\", color=\"red\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
